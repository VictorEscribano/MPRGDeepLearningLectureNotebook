{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProgramWorkBook_ImageClassfication",
      "provenance": [],
      "mount_file_id": "14EYXaEaw3qs3LMpFn0lcayrDIRcX-f4D",
      "authorship_tag": "ABX9TyNKOvj3JvGYyG8g5y/oxCjy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/20_workbook/ProgramWorkBook_ImageClassfication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# プログラム記述練習：画像分類編\n",
        "\n",
        "\n",
        "まずはこのプログラムをコピーして自分のGoogleドライブへと保存しましょう．\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ddoGSrzhJa-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. データのダウンロード\n",
        "\n",
        "プログラムに必要なデータをダウンロードします．\n",
        "\n",
        "**今回使用するデータは，今までと同様にMNISTデータセットですが，異なるデータの構造となっています．今回のデータのファイル構造は実際のデータ収集を行い，学習や評価に使用するために整理されたデータを想定して作成しています．**"
      ],
      "metadata": {
        "id": "kKesHBMzJt9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1dlrHQ0bqgs98q-gYoxJbI4YqUp0brNuA', 'MNIST_dataset.zip', quiet=False)\n",
        "!unzip -q -o MNIST_dataset.zip"
      ],
      "metadata": {
        "id": "5nzh5O2NJuU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで，一度データセットを確認してみましょう．\n",
        "\n",
        "データを確認すると，MNIST_datasetのフォルダ名trainとtestフォルダがあり，その中に0 ~ 9のフォルダがあります．\n",
        "\n",
        "それぞれの0 ~ 9のフォルダの中には，各クラスに対応した画像データがpng画像として1枚ずつ保存されています．\n",
        "\n",
        "![mnistfolder.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/d76cc9e1-a36c-8065-51b7-8e55c385b751.png)\n",
        "\n",
        "**注意点：オリジナルのMNIST Datsetについて**\n",
        "\n",
        "オリジナルのデータセットでは，1枚ずつの画像ではなく，バイナリデータとして画像データがまとめて保存されています．\n",
        "これまでに使用してきた`torchvision.datasets.MNIST`では，このバイナリデータを自動的にダウンロードして，読み込むことでデータセットを準備しています．\n",
        "\n",
        "MNIST datasetのWebサイト：\n",
        "http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "![MNIST original.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/b85f2d0a-1120-438f-c5e3-21e2e2598450.png)"
      ],
      "metadata": {
        "id": "csBG4hhM8K_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. モジュールのインポート部分\n",
        "\n",
        "こちらにプログラムに必要なモジュールのインポートを記述しましょう．\n",
        "\n",
        "※ プログラムが一通り完成した後に記述します．"
      ],
      "metadata": {
        "id": "xWEBw90-JicW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "075YmbGiJcaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. データセットクラスの作成\n",
        "\n",
        "ここでは，ダウンロードしたMNISTデータセットの形式に合わせて，PyTorchのデータセットクラスを自作します．\n"
      ],
      "metadata": {
        "id": "7vihckK95ukT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### この部分で使用する関数・クラスの動作確認"
      ],
      "metadata": {
        "id": "FqwKWIIgDP37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "### パスの作成 (os.path.join)\n",
        "_path = os.path.join(\"./directory\", \"sub_directory/subsub_directory\", \"file\")\n",
        "print(\"os.path.joinの結果:\", _path, \"\\n--------------------\")\n",
        "\n",
        "### ファイル一覧の取得 (glob)\n",
        "_glob_result1 = glob.glob(\"./MNIST_dataset/*\")\n",
        "print(\"globの結果1: \", _glob_result1, \"\\n--------------------\")\n",
        "\n",
        "_glob_result2 = glob.glob(\"./MNIST_dataset/train/*/*.png\")\n",
        "print(\"globの結果2:\", _glob_result2, \"\\n--------------------\")\n",
        "\n",
        "### 文字列の分割 (split)\n",
        "_filename = \"./MNIST_dataset/train/4/30167.png\"\n",
        "_split_filename = _filename.split(\"/\")\n",
        "print(\"文字列の分割結果:\", _split_filename, \"\\n--------------------\")\n",
        "\n",
        "### リストのIndexing（要素選択）\n",
        "_selected_split_filename = _split_filename[-2]  # 後ろから2番目\n",
        "print(\"リストのIndexingの結果:\", _selected_split_filename, \"\\n--------------------\")\n",
        "\n",
        "### 文字列 (str) --> 整数型 (int) への変換\n",
        "_int_data = int(_selected_split_filename)\n",
        "print(\"整数型への変換結果:\", _int_data)\n",
        "\n",
        "### 画像の読み込み (Python Image Library; PIL)\n",
        "_sample_image = Image.open(\"./MNIST_dataset/train/4/30167.png\")\n",
        "print(_sample_image, \"\\n--------------------\")   # 注意：画像は表示されません\n",
        "\n",
        "### PILで読み込んだ画像データの配列形式変換\n",
        "# 1. PIL Image --> Numpy array (今回は使いませんが頻繁に使用します)\n",
        "_numpy_image = np.array(_sample_image)\n",
        "print(\"image data as numpy array:\", _numpy_image, \"\\n--------------------\")\n",
        "\n",
        "# 2. PIL --> PyTorch Tensor (torchvisionの機能．画素値を自動的に0~255 --> 0.0 ~ 1.0に正規化しつつ変換します．)\n",
        "_to_tensor_class = ToTensor()\n",
        "_tensor_image = _to_tensor_class(_sample_image)\n",
        "print(\"image data as torch tensor:\", _tensor_image, \"\\n--------------------\")"
      ],
      "metadata": {
        "id": "ZsFMELYpDP81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上で確認した機能を使いつつ，データセットクラスを定義します．"
      ],
      "metadata": {
        "id": "83DqKOEBM8nY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iTAXxiLV72pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットクラスのデバッグ\n",
        "\n",
        "ここで，一度作成したデータセットクラスを呼び出して実行することで，正しく動作しているかを確認（デバッグ）します．\n",
        "\n",
        "**※ 細かなデバッグは非常に重要です．全てのプログラムを記述してからデバッグをしようとすると，原因の特定に時間がかかります．一つのクラス・関数などを作成したら，簡単なプログラムを記述してうまく動作するか確認をすることをお勧めします．**"
      ],
      "metadata": {
        "id": "lR3WVczH8aKM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8eWZqbp8aPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ネットワークモデルの定義\n",
        "\n",
        "続いてネットワークを定義します．\n",
        "畳み込みニューラルネットワークを定義します．"
      ],
      "metadata": {
        "id": "1jA21QAt_Lt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### この部分で使用する関数・クラスの動作確認"
      ],
      "metadata": {
        "id": "3VNIV7X-M3ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Tensor配列のサイズ確認\n",
        "x = torch.randn(10, 32, 7, 7)\n",
        "print(\"size of original x:\", x.size())\n",
        "\n",
        "# Tensor配列の並べ替え（サイズ変更）\n",
        "x_dst_1 = x.view(10, 32, 7*7)\n",
        "x_dst_2 = x.view(-1, 32*7*7)\n",
        "print(\"size of x_dst_1:\", x_dst_1.shape)\n",
        "print(\"size of x_dst_2:\", x_dst_2.shape)"
      ],
      "metadata": {
        "id": "jidE-V6QNIxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上で確認した機能を使いつつ，ネットワーククラスを定義します．\n",
        "\n",
        "この時，各レイヤーのクラスの詳細などを調べたい場合は，PyTorchのReferenceを参照しつつ実装します．\n",
        "\n",
        "[PyTorch reference mannual](https://pytorch.org/docs/stable/index.html)"
      ],
      "metadata": {
        "id": "D-wx5FkdNKA9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vvn0AxUp_T2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ネットワーククラスのデバッグ\n",
        "\n",
        "ここで，一度作成したネットワーククラスを呼び出して実行することで，正しく動作しているかを確認（デバッグ）します．"
      ],
      "metadata": {
        "id": "BZVEYnm3qj5G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TK5lvnJUqkAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 学習の準備\n",
        "\n",
        "ここでは，学習に必要な\n",
        "\n",
        "* ネットワークモデル\n",
        "* 誤差関数\n",
        "* 最適化手法\n",
        "* データセット\n",
        "\n",
        "の定義を行います．\n",
        "\n",
        "最適化関数などもReference mannualを参照しつつ好きなものを選択記述しましょう．\n",
        "\n",
        "**DataLoaderのnum_workersについて**\n",
        "\n",
        "`torch.utils.data.DataLoader`の引数である`num_workers`は，データを読み込んで準備する処理を並列処理するための引数です．例えば，`num_workers=10`とした場合には，10並列でデータの読込処理 (データセットクラスの`__getitem__()`) を10並列で実行してくれます．そのため，使用する計算機のCPU性能に合わせて，ある程度大きな数を指定しておくとデータの読込処理が早くなり，学習の高速化が期待できます．"
      ],
      "metadata": {
        "id": "mTJDAra7qkG2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6uikNw5qkN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 学習の開始\n",
        "\n",
        "上で定義したモデルや最適化手法，データセットを用いて学習を行います．"
      ],
      "metadata": {
        "id": "WwZK23CfcxpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### この部分で使用する関数・クラスの動作確認"
      ],
      "metadata": {
        "id": "HBj1RQQvrvt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### PyTorchのTensor (配列) 操作\n",
        "_output_sample = torch.rand([2, 10], dtype=torch.float32)\n",
        "print(\"network output (example):\", _output_sample)\n",
        "\n",
        "### argmax (最大値の要素をもつ配列のインデックスを返す)\n",
        "_predicted_class = _output_sample.argmax(dim=1)  # 1-次元目方向（横方向）にargmax\n",
        "print(\"predicted class (example):\", _predicted_class)\n",
        "\n",
        "### item (tensorのとある一つの要素をscalerとして返す)\n",
        "_sample_tensor = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "print(\"return as scaler:\", _sample_tensor[0].item())\n",
        "\n",
        "### 上のセルで定義したネットワークモデルのパラメータ（+そのほか）の抽出\n",
        "print(list(model.parameters()))   # 学習するモデルパラメータ（optimizerへ入力する時に使用することが多い）\n",
        "print(\"----------------\")\n",
        "print(model.state_dict())         # 学習するパラメータ + 学習はしないけど学習や推論処理を行うことで変化するパラメータ\n",
        "                                  #  (BatchNormの内部パラメータなど)（モデルの保存などに使用されることが多い）\n",
        "print(\"----------------\")\n",
        "\n",
        "### PyTorchのtensorのファイル保存\n",
        "_save_data = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "torch.save(_save_data, \"sample_data.pt\")\n",
        "\n",
        "### PyTorchのtensorのファイルの読込\n",
        "_load_data = torch.load(\"sample_data.pt\")\n",
        "print(_load_data)"
      ],
      "metadata": {
        "id": "wIC99H7h_T7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の関数を活用して学習ループを記述します．"
      ],
      "metadata": {
        "id": "0KZB8kCnem48"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vy3_38fBcxut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習経過のテキスト保存とグラフ化\n",
        "\n",
        "**テキスト保存**\n",
        "\n",
        "ログ（コンソール・ターミナル部分）に学習中の誤差の推移などを表示することで，学習の様子を確認できますが，Colaboratoryの再起動や再度学習を行うことでログは消えてしまい．後程，学習経過を確認・比較することができなくなります．\n",
        "そのため，学習経過の数値をテキストファイルなどで保存しておくと，非常に便利です．\n",
        "異なるネットワークや学習パラメータを用いて学習を行った場合との比較などを行うことができます．\n",
        "\n"
      ],
      "metadata": {
        "id": "2FdKqOjVQT3y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3BzLcLExQUDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**グラフ化**\n",
        "\n",
        "実行結果の数値を見ることで学習の様子が確認できますが，グラフ化することでより直感的に学習の挙動を理解することができます．\n",
        "ここでは，上の学習プログラム中で保存しておいた，1 epochごとの誤差とテストデータに対する精度をグラフ化して確認してみます．"
      ],
      "metadata": {
        "id": "GZSC93ghSegg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOgk8-qISenP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 評価\n",
        "\n",
        "学習したモデルを用いて評価を行います．"
      ],
      "metadata": {
        "id": "UW9Hxbf4fDr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの読み込み\n",
        "\n",
        "学習中に保存したモデルを読み込みます．\n",
        "\n"
      ],
      "metadata": {
        "id": "kmVKhPZGes1A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YseVLM-lrvyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "読み込んだ学習済みモデルでテストデータを認識して，認識率を算出します．"
      ],
      "metadata": {
        "id": "wHikRHvtgWCf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2oO_UVmEfD0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}