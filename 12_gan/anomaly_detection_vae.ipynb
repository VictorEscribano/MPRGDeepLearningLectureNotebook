{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/12_gan/anomaly_detection_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb46f71-5780-4294-b210-b57e2f2141b4",
      "metadata": {
        "id": "ffb46f71-5780-4294-b210-b57e2f2141b4"
      },
      "source": [
        "# 繰り返し処理による異常検知\n",
        "\n",
        "---\n",
        "## 目的\n",
        "\n",
        "Variational Autoencoder (VAE) を用いた繰り返し処理による異常検知の仕組みについて理解する．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57223e24-83f1-40f4-aabd-1139845a3a34",
      "metadata": {
        "id": "57223e24-83f1-40f4-aabd-1139845a3a34"
      },
      "source": [
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートします．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`GPU availability: True`と表示されれば，GPUを使用した計算を行うことが可能です．\n",
        "Falseとなっている場合は，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c785c9a4-bb12-47f0-bae5-2983bc13f510",
      "metadata": {
        "id": "c785c9a4-bb12-47f0-bae5-2983bc13f510"
      },
      "outputs": [],
      "source": [
        "# モジュールのインポート\n",
        "import os\n",
        "from time import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3398b0-4016-42ce-a672-ad9a4970768e",
      "metadata": {
        "id": "ff3398b0-4016-42ce-a672-ad9a4970768e"
      },
      "source": [
        "## データセット（MVTec-AD）\n",
        "\n",
        "この演習では，[MVTec Anomaly Detection (MVTec-AD) Dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad)を使用します．\n",
        "\n",
        "MVTec-AD Datasetは，異常検知評価データセットです．\n",
        "このデータセットには下図に示すような，さまざまな種類の物体の画像データが含まれており，それぞれ正常，異常の画像データが含まれています．\n",
        "今回はこのデータのうち，「capsule」のデータを例に異常検知を行います．\n",
        "\n",
        "![MVTec-AD.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/f608231e-295c-8f31-b48c-d9f46e6a3aad.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットのダウンロード\n",
        "\n",
        "下記のURLからMVTec-ADの「capsule」の画像データをダウンロードします．\n",
        "\n",
        "※ オリジナルのMVTec-ADの画像サイズは1枚あたり1024x1024 pixelsですが，ファイルサイズの削減などの観点から，下記のzipファイル内の画像サイズは512x512 pixelsとしています．\n",
        "\n",
        "解凍したzipファイルの中身を表示して確認します．\n",
        "まず，capsuleというフォルダがあり，この中に画像データがあります．\n",
        "さらに，この中に学習用データの`train`フォルダや評価用データの`test`フォルダがあります．\n",
        "`test`フォルダの中には，欠陥の種類ごとに画像フォルダが分かれており，いくつかの画像データが格納されています．"
      ],
      "metadata": {
        "id": "f4-a9_FcAjAa"
      },
      "id": "f4-a9_FcAjAa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fc10efa-9003-450f-91ad-1ff4c7387cf2",
      "metadata": {
        "id": "6fc10efa-9003-450f-91ad-1ff4c7387cf2"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1iYsTe0OVD3dawP7HWsMZp7YDlzkwDllG', 'anomaly_detection_data.zip', quiet=True)\n",
        "!unzip -q anomaly_detection_data.zip\n",
        "\n",
        "!echo \"directory ==============\"\n",
        "!ls anomaly_detection_data\n",
        "!ls anomaly_detection_data/capsule\n",
        "!ls anomaly_detection_data/capsule/train/\n",
        "!ls anomaly_detection_data/capsule/test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データセットクラスの作成\n",
        "\n",
        "次に，このMVTec-ADを読み込むためのデータセットクラスを定義します．\n",
        "ここでは`MVTecAD`というクラス名で，定義を行います．\n",
        "\n",
        "まず，`__init__`で，読み込む画像のフォルダを指定する`image_dir`と画像に対する前処理を定義する`transform`を引数として読みこみます．\n",
        "\n",
        "そして，`__getitem__`では，指定された番号`i`番目の画像を読み込み，必要に応じて前処理を行ってから画像データを返すよう定義します．"
      ],
      "metadata": {
        "id": "eQG-uEv6C5R0"
      },
      "id": "eQG-uEv6C5R0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e3ecdc-d547-440b-bf0c-3ee15507f2cf",
      "metadata": {
        "id": "02e3ecdc-d547-440b-bf0c-3ee15507f2cf"
      },
      "outputs": [],
      "source": [
        "class MVTecAD(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dir, transform):\n",
        "        self.transform = transform\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.image_dir))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        filename = '{:0>3}.png'.format(i)\n",
        "        image = Image.open(os.path.join(self.image_dir, filename))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.zeros(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e251951a-d7ae-4c92-bde1-47bff779b75c",
      "metadata": {
        "id": "e251951a-d7ae-4c92-bde1-47bff779b75c"
      },
      "source": [
        "## ネットワークモデル\n",
        "\n",
        "次にVAEのネットワークモデルを定義します．\n",
        "ここでは，繰り返し処理による異常検知の論文 [1] で使用されている構造と同様のネットワークを定義します．\n",
        "少し大きな構造ですが，Encoder, Decoderそれぞれ，8層の畳み込みからなるVAEを定義します．\n",
        "その他はこれまでのAE, VAEの演習と同様の処理を定義します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c07cb6-10ee-46fa-bb9f-dd8b5417eb1a",
      "metadata": {
        "id": "f9c07cb6-10ee-46fa-bb9f-dd8b5417eb1a"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim=100, input_c=1):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "                nn.Conv2d(input_c, 32, kernel_size=4, stride=2, padding=1), # 128 -> 64\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(32, 32, kernel_size=4, stride=2, padding=1),      # 64 -> 32\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),      # 32 -> 32\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),      # 32 -> 16\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),      # 16 -> 16\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),     # 16 -> 8\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),     # 8 -> 8\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),      # 8 -> 8\n",
        "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "                nn.Conv2d(32, z_dim, kernel_size=8, stride=1)               # 8 -> 1\n",
        "            )\n",
        "\n",
        "        self.mu_fc = nn.Linear(z_dim, z_dim)\n",
        "        self.logvar_fc = nn.Linear(z_dim, z_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=8, mode='nearest'),\n",
        "            nn.Conv2d(z_dim, 32, kernel_size=3, stride=1, padding=1),  # 1 -> 8\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),     # 8 -> 8\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),    # 8 -> 8\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),    # 8 -> 16\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),     # 16 -> 16\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),     # 16 -> 32\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),     # 32 -> 32\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),     # 32 -> 64\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(32, input_c, kernel_size=3, stride=1, padding=1),  # 64 -> 128\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def initialize(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.LayerNorm):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def forward(self, x):\n",
        "        h      = self.encoder(x)\n",
        "\n",
        "        h = torch.flatten(h, start_dim=1)\n",
        "        mu     = self.mu_fc(h)                    # 平均ベクトル\n",
        "        logvar = self.logvar_fc(h)                # 分散共分散行列の対数\n",
        "        z      = self.reparameterize(mu, logvar)  # 潜在変数\n",
        "\n",
        "        x_hat  = self.decoder(z.view(z.size(0), -1, 1, 1))\n",
        "        self.mu     = mu.squeeze()\n",
        "        self.logvar = logvar.squeeze()\n",
        "        return x_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット・ネットワークモデル・最適化手法・誤差関数の設定\n",
        "\n",
        "次に，学習を開始するための，データセット，ネットワークモデル，最適化手法，誤差関数を設定します．\n",
        "\n",
        "データセットの設定では，学習データのバリエーションを増幅させるために，transformに画像変換の処理を加えた前処理を定義します．\n",
        "\n",
        "\n",
        "誤差関数に関しては，前回行ったVAEと同様の誤差関数を定義して使用します．"
      ],
      "metadata": {
        "id": "T3Au-PfAD2vx"
      },
      "id": "T3Au-PfAD2vx"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "# データセットの設定\n",
        "transform = transforms.Compose([\n",
        "                transforms.Resize((128, 128)),\n",
        "                transforms.RandomAffine(degrees=[-60, 60], translate=(0.1, 0.1), scale=(0.5, 1.5)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomVerticalFlip(p=0.5),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "train_data = MVTecAD(image_dir=\"./anomaly_detection_data/capsule/train/good\", transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# ネットワークモデル・最適化手法の設定\n",
        "model = VAE(z_dim=100, input_c=3)\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, betas=(0.5, 0.999), weight_decay=1e-5)\n",
        "\n",
        "# 誤差関数\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    recon = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon + kl_div"
      ],
      "metadata": {
        "id": "VyV3aohBD20p"
      },
      "id": "VyV3aohBD20p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "499b6ff5-f689-4643-ba8f-fb5ba2225750",
      "metadata": {
        "id": "499b6ff5-f689-4643-ba8f-fb5ba2225750"
      },
      "source": [
        "## 学習\n",
        "\n",
        "学習を開始します．\n",
        "学習自体は通常のVAEと同様に画像を再構成するよう学習を行います．\n",
        "\n",
        "※ **この学習は非常に時間がかかり演習時間内に終えることが難しいため，学習の演算を割愛し，学習済みモデルを用いて異常検知の確認を行います．**\n",
        "ご興味のある方は，講義終了後にご自身でうごかしてみてください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba30206-8068-4f26-b5b5-af85c04fce11",
      "metadata": {
        "id": "9ba30206-8068-4f26-b5b5-af85c04fce11"
      },
      "outputs": [],
      "source": [
        "epochs = 1000\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for idx, (inputs, _) in enumerate(train_loader):\n",
        "        if use_cuda:\n",
        "            inputs = inputs.cuda()\n",
        "        output = model(inputs)\n",
        "        loss = loss_function(output, inputs, model.mu, model.logvar)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % 100 == 0 and epoch % 10 == 0:\n",
        "            print('%d epoch [%d/%d] | loss: %.4f |' % (epoch, idx, len(train_loader), loss.item()))\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        torch.save(model.state_dict(), \"anomaly_det_model_%04d.pt\" % epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86c2453f-f6a3-4d1d-9472-cc081d63fbd6",
      "metadata": {
        "id": "86c2453f-f6a3-4d1d-9472-cc081d63fbd6"
      },
      "source": [
        "## VAEによる画像の再構成結果の確認\n",
        "\n",
        "\n",
        "異常検知を行う前に，上記の学習により，正しく画像が再構成できているかを確認します．\n",
        "まず，欠陥のある画像データを読み込むよう，`test_bad_data`および`test_loader`を定義します．\n",
        "\n",
        "そして，欠陥画像をVAEへと入力して得られた再構成画像を可視化して確認します．\n",
        "\n",
        "結果は左から，入力画像，VAEからの出力画像，その2つの画像の差分（絶対値）です．\n",
        "\n",
        "ボケた画像が生成されますが，ある程度正しい形状や色を保った画像が出力されていることがわかります．\n",
        "また，大きな割れ目のある部分は差分が大きくなっていることがわかります．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2ed53df-0b92-4899-b650-632e485f5b38",
      "metadata": {
        "id": "c2ed53df-0b92-4899-b650-632e485f5b38"
      },
      "outputs": [],
      "source": [
        "# 学習済みモデルの読み込み\n",
        "model.load_state_dict(torch.load(\"./anomaly_detection_data/trained_model.pt\"))\n",
        "\n",
        "transform_test = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])\n",
        "test_bad_data = MVTecAD(image_dir=\"./anomaly_detection_data/capsule/test/crack\", transform=transform_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_bad_data, batch_size=1, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for ind, (inputs, _) in enumerate(test_loader):\n",
        "        if use_cuda:\n",
        "            inputs = inputs.cuda()\n",
        "\n",
        "        reconstructed = model(inputs).detach()\n",
        "        b = inputs.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "\n",
        "        a = reconstructed.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "\n",
        "        diff = np.abs(a - b)\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(b, cmap='gray', vmin = 0, vmax = 1, interpolation='none')\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(a, cmap='gray', vmin = 0, vmax = 1, interpolation='none')\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(diff, interpolation='none')\n",
        "        plt.show()\n",
        "\n",
        "        if ind == 2:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e563bfed-2b9d-4075-af21-eab21695ceda",
      "metadata": {
        "id": "e563bfed-2b9d-4075-af21-eab21695ceda"
      },
      "source": [
        "## 繰り返しによる異常検知\n",
        "\n",
        "それでは次に，このVAEを用いて繰り返し処理による異常検知を行います．\n",
        "\n",
        "まず，欠陥のある画像データを読み込むための`test_bad_data`および`test_loader`を定義します．\n",
        "\n",
        "\n",
        "異常検知の処理の流れは次のようになります．\n",
        "\n",
        "まず1枚の画像を用意します．\n",
        "次に，その画像をVAEへと入力し，出力画像と元画像の差（MSE）を計算し，$E(x_t)$とします．\n",
        "そして，その勾配$\\nabla E(x_t)$と二乗誤差$(x_t - f_{VAE} (x_t))^2$の積を入力画像へ加えることで新たな画像$x_t$を生成します．\n",
        "\n",
        "この$x_t$を再度VAEへと入力して同様の手順を繰り返すことで，異常部分が徐々に再構成され正常な画像へと近づいていきます．\n",
        "\n",
        "\n",
        "![a.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/09698b6d-1b24-cc9f-abf2-b6f43c3cf2c7.jpeg)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e804250-1f9e-4748-b8d3-d38611eddfc6",
      "metadata": {
        "id": "5e804250-1f9e-4748-b8d3-d38611eddfc6"
      },
      "outputs": [],
      "source": [
        "max_iter = 99\n",
        "alpha = 0.5\n",
        "lam = 0.05\n",
        "decay_rate = 0.1\n",
        "minimum = 1e12\n",
        "th = 0.5\n",
        "\n",
        "transform_test = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
        "test_bad_data = MVTecAD(image_dir=\"./anomaly_detection_data/capsule/test/crack\", transform=transform_test)\n",
        "test_bad_loader = torch.utils.data.DataLoader(test_bad_data, batch_size=1, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "mse_loss = nn.MSELoss(reduction='sum')\n",
        "if use_cuda:\n",
        "    mse_loss = mse_loss.cuda()\n",
        "\n",
        "for index, (x_org, _) in enumerate(test_bad_loader):\n",
        "    # 2つ目のサンプルを例として実行するため，1つ目を飛ばして実行\n",
        "    if index == 0:\n",
        "        continue\n",
        "\n",
        "    img = x_org[0].data.numpy()\n",
        "\n",
        "    x_t_images = []\n",
        "    grad_images = []\n",
        "    reconstructed_images = []\n",
        "\n",
        "    if use_cuda:\n",
        "        x_org = x_org.cuda()\n",
        "\n",
        "    x_org.requires_grad_(True)\n",
        "    rec_x = model(x_org).detach()\n",
        "\n",
        "    loss = mse_loss(x_org, rec_x)\n",
        "    loss.backward()\n",
        "    grads = x_org.grad.data\n",
        "    x_t = x_org - alpha*grads*(x_org - rec_x)**2\n",
        "\n",
        "    grad_images.append(grads[0].cpu().numpy().transpose(1,2,0))\n",
        "    reconstructed_images.append(rec_x[0].data.cpu().numpy().transpose(1,2,0))\n",
        "    x_t_images.append(x_t[0].data.cpu().numpy().transpose(1,2,0))\n",
        "\n",
        "    losses = torch.zeros(max_iter)\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        x_t = Variable(x_t.clamp(min=0, max=1), requires_grad=True)\n",
        "        rec_x = model(x_t).detach()\n",
        "        rec_loss = mse_loss(x_t, rec_x)\n",
        "        losses[i] = rec_loss.item()\n",
        "\n",
        "        if minimum <= rec_loss:\n",
        "            minimum = min(minimum, rec_loss)\n",
        "        if rec_loss <= th:\n",
        "            break\n",
        "\n",
        "        l1 = torch.abs(x_t - x_org).sum()\n",
        "        loss = rec_loss + lam*l1\n",
        "        loss.backward()\n",
        "        grads = x_t.grad.data\n",
        "\n",
        "        mask = (x_t - rec_x)**2\n",
        "        energy = grads * mask\n",
        "\n",
        "        x_t = x_t - alpha*energy\n",
        "\n",
        "        grad_images.append(grads[0].cpu().numpy().transpose(1,2,0))\n",
        "        reconstructed_images.append(rec_x[0].data.cpu().numpy().transpose(1,2,0))\n",
        "        x_t_images.append(x_t[0].data.cpu().numpy().transpose(1,2,0))\n",
        "\n",
        "    break  # 1サンプル分の処理が終わった段階でforループを抜ける"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 結果の表示\n",
        "\n",
        "上記の処理で得られた結果を可視化して確認します．\n",
        "\n",
        "まず，オリジナルの入力画像と繰り返し処理で得られた画像$x_t$を可視化します．\n",
        "\n",
        "結果を確認すると，繰り返し処理を行うことで，欠陥部分が徐々に復元され，正常な画像へと近づいていることがわかります．\n"
      ],
      "metadata": {
        "id": "JlXVvQM5KGkL"
      },
      "id": "JlXVvQM5KGkL"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img.transpose(1, 2, 0), vmin = 0, vmax = 1, interpolation='none')\n",
        "plt.title(\"orig image\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(30, 30))\n",
        "for i, x_t_img in enumerate(x_t_images):\n",
        "    plt.subplot(10, 10, i+1)\n",
        "    plt.imshow(x_t_img, vmin = 0, vmax = 1, interpolation='none')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LQmlar5IKGnt"
      },
      "id": "LQmlar5IKGnt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 類似度（SSIM）による欠陥領域の可視化\n",
        "\n",
        "入力画像と繰り返し処理で得られた画像の類似度の差から，欠陥領域の特定を行います．\n",
        "\n",
        "ここでは，類似どの指標としてStructural Similarity (SSIM) とStructural Dissimilarity (DSSIM) を使用します．\n",
        "\n",
        "元画像`input_image`と，n回目の反復で得られた画像`n_iter_image`のSSIMを計算します．\n",
        "ここで，SSIMの計算には，Pythonのscikit-imageの関数を活用します．\n",
        "\n",
        "この関数を適用することで．画像全体での類似度`ssim`と微小領域（小さなパッチ）ごとの類似度`ssim_img`を獲得します．\n",
        "\n",
        "DSSIMはSSIMの逆の関係性を示した指標のため，`1 - ssim`を行うことで獲得できます．\n",
        "\n",
        "この微小領域ごとのDSSIMを可視化すると，欠陥領域に高いDSSIMの値となっていることがわかります．\n",
        "このようにすることで欠陥領域を特定することが可能となります．\n"
      ],
      "metadata": {
        "id": "0nXvPMA9WChd"
      },
      "id": "0nXvPMA9WChd"
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "iter_index = 10  # 何回目の反復画像と比較するか\n",
        "\n",
        "input_image = np.mean(img.transpose(1, 2, 0), axis=2)\n",
        "n_iter_image = np.mean(x_t_images[iter_index], axis=2)\n",
        "\n",
        "ssim_value, ssim_img = ssim(input_image, n_iter_image, win_size=5, multichannel=False, full=True)\n",
        "dssim = 1. - ssim_value\n",
        "dssim_img = 1. - ssim_img\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(input_image, cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(n_iter_image, cmap='gray', vmin=0, vmax=1, interpolation='none')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(dssim_img, vmin=0, vmax=1, interpolation='none')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zb3YQLVfLEvP"
      },
      "id": "Zb3YQLVfLEvP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2231e4dd-8ef3-4f48-ada8-4a486188d438",
      "metadata": {
        "id": "2231e4dd-8ef3-4f48-ada8-4a486188d438"
      },
      "source": [
        "## 課題\n",
        "\n",
        "1. その他の画像（正常や他の異常画像）に対する結果を確認しましょう．\n",
        "2. 反復回数を増加させたときにどのような再構成画像が生成されるか確認しましょう．"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f4b3ced-9d4b-4e14-81dd-62ca078fb2b6",
      "metadata": {
        "id": "8f4b3ced-9d4b-4e14-81dd-62ca078fb2b6"
      },
      "source": [
        "## 参考文献\n",
        "\n",
        "[1] David Dehaene, Oriel Frigo, Sébastien Combrexelle, Pierre Eline, \"Iterative energy-based projection on a normal data manifold for anomaly localization,\" in ICLR, 2020."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "anomaly_detection_vae.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}