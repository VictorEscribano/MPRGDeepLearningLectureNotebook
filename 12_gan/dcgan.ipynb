{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "03_Deep_Convolutional_GAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/12_gan/dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hMYxHFHeE9o"
      },
      "source": [
        "# Deep Convolutional Generative Adversarial Networks (DC-GAN)\n",
        "## 目的\n",
        "DC-GANによって画像の生成をして動作を理解する．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL9fMQrC6C4v"
      },
      "source": [
        "## モジュールのインポート\n",
        "\n",
        "はじめに必要となるモジュールをインポートします．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`GPU availability: True`と表示されれば，GPUを使用した計算を行うことが可能です．\n",
        "Falseとなっている場合は，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uTXbOYTeE9o"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub7VJ3DFeE9s"
      },
      "source": [
        "## ネットワークの構築\n",
        "オリジナルのGANは，全結合層とReLUのみで構築される非常にシンプルなネットワークでした．\n",
        "シンプルな反面，学習が不安定になったり，高解像な画像生成は難しいという問題がありました．\n",
        "\n",
        "Deep Convolutional GAN (DC-GAN)は，名前の通り畳み込み処理を用いたネットワークの構築することによって，オリジナルのGANより綺麗な画像を生成することを可能としています．\n",
        "\n",
        "また，DC-GANは，以下に示す点でもオリジナルのGANと異なります．\n",
        "* Batch Normalizationを利用する．（Discriminatorの1層目と最終層は除く）\n",
        "* Discriminatorの活性化関数は，Leaky ReLUを使用する．\n",
        "* Generatorの最終層はtanh関数を使用する．（それ以外の層は全てReLU）\n",
        "* Deconvolutionの使用，PoolingではなくConvolutionによるDownsampling\n",
        "\n",
        "これらを考慮してDiscriminatorとGeneratorのネットワークを構築します．\n",
        "このとき，入力引数として`img_size`を指定します．\n",
        "これは生成する画像サイズを指定する引数です．\n",
        "この値に応じて，畳み込みの数を適応的に設定し，ネットワークを構築します．\n",
        "GeneratorとDiscriminator共に重みパラメータは平均が0，偏差が0.02の正規分布で，バイアスは0で初期化します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KET06Es1eE9s"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, out_ch=3, img_size=32):\n",
        "        super(Generator, self).__init__()\n",
        "        n_layer = int(np.log2(img_size)) - 2\n",
        "        self.model = nn.Sequential()\n",
        "\n",
        "        features = 512\n",
        "        self.model.add_module('Deconv_first', nn.ConvTranspose2d(latent_dim, features, 2, 2, bias=True))\n",
        "        self.model.add_module('BN_first', nn.BatchNorm2d(features))\n",
        "        self.model.add_module('Act_first', nn.ReLU(inplace=True))\n",
        "\n",
        "        in_features = features\n",
        "        for i in range(n_layer):\n",
        "            out_features = in_features // 2\n",
        "            self.model.add_module('Deconv%d' % i, nn.ConvTranspose2d(in_features, out_features, 4, 2, 1, bias=True))\n",
        "            self.model.add_module('BN%d' % i, nn.BatchNorm2d(out_features))\n",
        "            self.model.add_module('Act%d' % i, nn.ReLU(inplace=True))\n",
        "            in_features = out_features\n",
        "\n",
        "        self.model.add_module('Deconv_last', nn.ConvTranspose2d(in_features, out_ch, 2, 2, bias=True))\n",
        "        self.model.add_module('Act_last', nn.Tanh())\n",
        "        self.weight_init()\n",
        "\n",
        "    def weight_init(self):\n",
        "        for m in self.model:\n",
        "          if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "            m.weight.data.normal_(0.0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_ch=3, img_size=32):\n",
        "        super(Discriminator, self).__init__()\n",
        "        n_layer = int(np.log2(img_size)) - 2\n",
        "        self.model = nn.Sequential()\n",
        "\n",
        "        features = 32\n",
        "        self.model.add_module('Conv_first', nn.Conv2d(in_ch, features, 4, 2, 1, bias=True))\n",
        "        self.model.add_module('Act_first', nn.LeakyReLU(negative_slope=0.2))\n",
        "\n",
        "        in_features = features\n",
        "        for i in range(n_layer):\n",
        "            out_features = in_features * 2\n",
        "            self.model.add_module('Conv%d' % i, nn.Conv2d(in_features, out_features, 4, 2, 1, bias=True))\n",
        "            self.model.add_module('BN%d' % i, nn.BatchNorm2d(out_features))\n",
        "            self.model.add_module('Act%d' % i, nn.LeakyReLU(negative_slope=0.2))\n",
        "            in_features = out_features\n",
        "\n",
        "        self.model.add_module('Conv_last', nn.Conv2d(in_features, 1, 2, 1, bias=True))\n",
        "        self.weight_init()\n",
        "\n",
        "    def weight_init(self):\n",
        "        for m in self.model:\n",
        "          if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "            m.weight.data.normal_(0.0, 0.02)\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ata4tGheE9v"
      },
      "source": [
        "## データセットと最適化関数\n",
        "データセットにはMNISTを使用します．\n",
        "最適化関数はAdam optimizer使用し，学習率$2\\times 10^4$，betaの値を$0.5, 0.999$として学習します．\n",
        "\n",
        "最後に，構築したネットワークモデルの詳細を表示します．\n",
        "指定した`img_size`の値に応じて畳み込みの数が変わります．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWYLuDW6eE9v"
      },
      "source": [
        "# データセットの設定\n",
        "transform_training = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor()])\n",
        "mnist_data = datasets.MNIST(root='./data', train=True, transform=transform_training, download=True)\n",
        "training_data = DataLoader(mnist_data, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "latent_dim = 100\n",
        "G = Generator(latent_dim=latent_dim, out_ch=1, img_size=32)\n",
        "D = Discriminator(in_ch=1, img_size=32)\n",
        "if use_cuda:\n",
        "    G = G.cuda()\n",
        "    D = D.cuda()\n",
        "opt_g = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "opt_d = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "print('=' * 50)\n",
        "print(G)\n",
        "print('=' * 50)\n",
        "print(D)\n",
        "print('=' * 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea60zVkueE9z"
      },
      "source": [
        "## GANの学習\n",
        "\n",
        "GANの学習を行います．\n",
        "学習のプロセスは，オリジナルのGANと同じため，説明は割愛します．\n",
        "\n",
        "※ **こDC-GANはオリジナルのGANよりも演算量が増えるため学習に時間がかかります．演習では学習を割愛し，学習済みモデルを用いて画像の生成結果を確認します．**\n",
        "ご興味のある方は，講義終了後にご自身でうごかしてみてください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meu9G0CPeE9z"
      },
      "source": [
        "n_epoch = 20\n",
        "n_critic = 1\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(1, n_epoch+1):\n",
        "    Tensor = torch.cuda.FloatTensor\n",
        "    G.train()\n",
        "    D.train()\n",
        "    for idx, (real_x, _) in enumerate(training_data):\n",
        "        if use_cuda:\n",
        "            real_x = real_x.cuda()\n",
        "        batch = real_x.size(0)\n",
        "        flag_real = Tensor(batch).fill_(1.0)\n",
        "        flag_fake = Tensor(batch).fill_(0.0)\n",
        "\n",
        "        for _ in range(n_critic):\n",
        "            D.zero_grad()\n",
        "            z = torch.randn(batch, latent_dim, 1, 1)\n",
        "            if use_cuda:\n",
        "                z = z.cuda()\n",
        "            fake_x = G(z)\n",
        "            out_real = D(real_x)\n",
        "            out_fake = D(fake_x.detach())\n",
        "            loss_real = criterion(out_real, flag_real)\n",
        "            loss_fake = criterion(out_fake, flag_fake)\n",
        "            dis_loss = loss_real + loss_fake\n",
        "            dis_loss.backward()\n",
        "            opt_d.step()\n",
        "\n",
        "        G.zero_grad()\n",
        "        z = torch.randn(batch, latent_dim, 1, 1)\n",
        "        if use_cuda:\n",
        "            z = z.cuda()\n",
        "        fake_x = G(z)\n",
        "        out_gen = D(fake_x)\n",
        "        gen_loss = criterion(out_gen, flag_real)\n",
        "        gen_loss.backward()\n",
        "        opt_g.step()\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print('Training epoch: {} [{}/{} ({:.0f}%)] | D loss: {:.6f} | G loss: {:.6f} |'\\\n",
        "                  .format(epoch, idx * len(real_x), len(training_data.dataset),\n",
        "                  100. * idx / len(training_data), dis_loss.item(), gen_loss.item()))\n",
        "\n",
        "    torch.save(G.state_dict(), \"G_%04d.pt\" % epoch)\n",
        "    torch.save(D.state_dict(), \"D_%04d.pt\" % epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習したGeneratorによる画像生成\n",
        "\n",
        "学習したGeneratorを用いて画像を生成します．\n",
        "\n",
        "まず，学習済みモデルのパラメータを読み込みます．\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ここでは，正規分布に従い乱数`z`を生成し，それをGeneratorへと入力することで，画像生成をおこない，その結果を表示します．\n",
        "\n",
        "適切な学習が行われている場合は，0~9の数字の画像が生成されます．"
      ],
      "metadata": {
        "id": "HvFlO_hAfJGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データのダウンロード\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1EUxuBqXVzm18rwlbU_FHk7NtYY9rc9Y0', 'dcgan_model.zip', quiet=True)\n",
        "!unzip -q dcgan_model.zip\n",
        "\n",
        "\n",
        "# 学習済みモデルの読み込み\n",
        "G.load_state_dict(torch.load(\"dcgan_model/G_0100.pt\"))\n",
        "D.load_state_dict(torch.load(\"dcgan_model/D_0100.pt\"))"
      ],
      "metadata": {
        "id": "W5RfJE6yf9dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJJMbAwpeE91"
      },
      "source": [
        "z = torch.randn(100, 100, 1, 1)\n",
        "if use_cuda:\n",
        "    z = z.cuda()\n",
        "\n",
        "G.eval()\n",
        "with torch.no_grad():\n",
        "    test_img = G(z)\n",
        "\n",
        "if use_cuda:\n",
        "    test_img = test_img.cpu()\n",
        "_test_img = (test_img * 256.).clamp(min=0., max=255.).squeeze().data.numpy()\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i, im in enumerate(_test_img):\n",
        "    ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(im, 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY2-w6Z1MTS1"
      },
      "source": [
        "## 課題\n",
        "1. データセットをMNISTからCIFAR-10に変更して学習してみましょう．\n",
        "2. 2つの潜在変数の間を補間するように画像生成した場合，どのような画像が生成されるか確認してください．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfKKH1rkplLp"
      },
      "source": [
        "# 参考文献\n",
        "[1] Alec Radford, Luke Metz and Soumith Chintala, Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, ICLR, 2016."
      ]
    }
  ]
}